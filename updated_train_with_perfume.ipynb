{"cells":[{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: statsmodels in c:\\python310\\lib\\site-packages (0.14.3)Note: you may need to restart the kernel to use updated packages.\n","\n","Requirement already satisfied: numpy<3,>=1.22.3 in c:\\python310\\lib\\site-packages (from statsmodels) (1.26.0)\n","Requirement already satisfied: scipy!=1.9.2,>=1.8 in c:\\python310\\lib\\site-packages (from statsmodels) (1.11.3)\n","Requirement already satisfied: pandas!=2.1.0,>=1.4 in c:\\python310\\lib\\site-packages (from statsmodels) (2.1.1)\n","Requirement already satisfied: patsy>=0.5.6 in c:\\python310\\lib\\site-packages (from statsmodels) (0.5.6)\n","Requirement already satisfied: packaging>=21.3 in c:\\python310\\lib\\site-packages (from statsmodels) (23.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in c:\\python310\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in c:\\python310\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.1 in c:\\python310\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2023.3)\n","Requirement already satisfied: six in c:\\python310\\lib\\site-packages (from patsy>=0.5.6->statsmodels) (1.16.0)\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip is available: 24.0 -> 24.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]}],"source":["pip install statsmodels"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import statsmodels.api as sm\n","import seaborn as sns\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import scale, StandardScaler\n","from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_predict\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_absolute_error, r2_score, roc_auc_score, roc_curve\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import SVC\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.model_selection import cross_val_score\n","from sklearn.ensemble import RandomForestClassifier\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["\n","class_names = {0: 'air', 1: 'coffe', 2: 'kolonya', 3: 'parfum'}\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore', category=DeprecationWarning)\n","warnings.filterwarnings('ignore', category=FutureWarning)\n","df = pd.read_csv(\"./dataset.csv\")"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>57</th>\n","      <th>58</th>\n","      <th>59</th>\n","      <th>60</th>\n","      <th>61</th>\n","      <th>62</th>\n","      <th>63</th>\n","      <th>64</th>\n","      <th>65</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>193443.4</td>\n","      <td>193025.0</td>\n","      <td>62197.5</td>\n","      <td>62178.2</td>\n","      <td>62154.7</td>\n","      <td>120557728.0</td>\n","      <td>83064704.0</td>\n","      <td>35546812.0</td>\n","      <td>35233.6</td>\n","      <td>35212.3</td>\n","      <td>...</td>\n","      <td>13322.7</td>\n","      <td>13316.7</td>\n","      <td>28250.9</td>\n","      <td>28263.9</td>\n","      <td>28268.2</td>\n","      <td>38435.5</td>\n","      <td>38352.7</td>\n","      <td>32.060001</td>\n","      <td>39.240002</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>191027.6</td>\n","      <td>191162.2</td>\n","      <td>60891.8</td>\n","      <td>60873.7</td>\n","      <td>60853.5</td>\n","      <td>6463676.5</td>\n","      <td>190329328.0</td>\n","      <td>55123896.0</td>\n","      <td>34696.6</td>\n","      <td>34673.1</td>\n","      <td>...</td>\n","      <td>13067.5</td>\n","      <td>13067.0</td>\n","      <td>27607.6</td>\n","      <td>27617.0</td>\n","      <td>27602.3</td>\n","      <td>38194.7</td>\n","      <td>38116.5</td>\n","      <td>32.070000</td>\n","      <td>39.369999</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>189542.3</td>\n","      <td>189866.0</td>\n","      <td>59630.6</td>\n","      <td>59602.4</td>\n","      <td>59548.2</td>\n","      <td>5929291.5</td>\n","      <td>36875408.0</td>\n","      <td>72806704.0</td>\n","      <td>34185.3</td>\n","      <td>34166.5</td>\n","      <td>...</td>\n","      <td>12853.5</td>\n","      <td>12854.0</td>\n","      <td>27064.8</td>\n","      <td>27050.9</td>\n","      <td>27013.5</td>\n","      <td>37990.1</td>\n","      <td>37968.3</td>\n","      <td>32.070000</td>\n","      <td>39.310001</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>188211.5</td>\n","      <td>188485.8</td>\n","      <td>58356.4</td>\n","      <td>58328.1</td>\n","      <td>58270.9</td>\n","      <td>5651954.0</td>\n","      <td>61505924.0</td>\n","      <td>41855980.0</td>\n","      <td>33689.2</td>\n","      <td>33682.3</td>\n","      <td>...</td>\n","      <td>12612.9</td>\n","      <td>12614.6</td>\n","      <td>26413.3</td>\n","      <td>26386.1</td>\n","      <td>26349.1</td>\n","      <td>37792.4</td>\n","      <td>37822.1</td>\n","      <td>32.080002</td>\n","      <td>39.290001</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>186701.1</td>\n","      <td>186905.7</td>\n","      <td>56990.8</td>\n","      <td>56938.5</td>\n","      <td>56899.0</td>\n","      <td>5407905.0</td>\n","      <td>420379552.0</td>\n","      <td>420379552.0</td>\n","      <td>33159.1</td>\n","      <td>33151.4</td>\n","      <td>...</td>\n","      <td>12382.2</td>\n","      <td>12381.7</td>\n","      <td>25788.4</td>\n","      <td>25750.4</td>\n","      <td>25722.9</td>\n","      <td>37629.9</td>\n","      <td>37693.7</td>\n","      <td>32.110001</td>\n","      <td>39.200001</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 67 columns</p>\n","</div>"],"text/plain":["          0         1        2        3        4            5            6  \\\n","0  193443.4  193025.0  62197.5  62178.2  62154.7  120557728.0   83064704.0   \n","1  191027.6  191162.2  60891.8  60873.7  60853.5    6463676.5  190329328.0   \n","2  189542.3  189866.0  59630.6  59602.4  59548.2    5929291.5   36875408.0   \n","3  188211.5  188485.8  58356.4  58328.1  58270.9    5651954.0   61505924.0   \n","4  186701.1  186905.7  56990.8  56938.5  56899.0    5407905.0  420379552.0   \n","\n","             7        8        9  ...       57       58       59       60  \\\n","0   35546812.0  35233.6  35212.3  ...  13322.7  13316.7  28250.9  28263.9   \n","1   55123896.0  34696.6  34673.1  ...  13067.5  13067.0  27607.6  27617.0   \n","2   72806704.0  34185.3  34166.5  ...  12853.5  12854.0  27064.8  27050.9   \n","3   41855980.0  33689.2  33682.3  ...  12612.9  12614.6  26413.3  26386.1   \n","4  420379552.0  33159.1  33151.4  ...  12382.2  12381.7  25788.4  25750.4   \n","\n","        61       62       63         64         65  label  \n","0  28268.2  38435.5  38352.7  32.060001  39.240002      0  \n","1  27602.3  38194.7  38116.5  32.070000  39.369999      0  \n","2  27013.5  37990.1  37968.3  32.070000  39.310001      0  \n","3  26349.1  37792.4  37822.1  32.080002  39.290001      0  \n","4  25722.9  37629.9  37693.7  32.110001  39.200001      0  \n","\n","[5 rows x 67 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["y = df[\"label\"]\n","X = df.drop([\"label\"], axis=1)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# Replace inf with NaN and then fill Nan with a very large ginit number\n","X.replace([np.inf, -np.inf], np.nan, inplace=True)\n","X.fillna(X.max().max(), inplace=True)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","# Split the data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["\n","from sklearn.preprocessing import StandardScaler\n","\n","# Initialize and fit scaler\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["['best_classifier.pkl']"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["import joblib\n","from sklearn.ensemble import RandomForestClassifier\n","\n","# Example model training\n","model = RandomForestClassifier()\n","model.fit(X_train_scaled, y_train)\n","\n","# Save the model\n","joblib.dump(model, 'best_classifier.pkl')\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training Logistic Regression...\n","Logistic Regression Accuracy: 1.0000\n","Classification Report for Logistic Regression:\n","               precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      1798\n","           1       1.00      1.00      1.00      1892\n","           2       1.00      1.00      1.00      1800\n","\n","    accuracy                           1.00      5490\n","   macro avg       1.00      1.00      1.00      5490\n","weighted avg       1.00      1.00      1.00      5490\n","\n","Training K-Nearest Neighbors...\n","K-Nearest Neighbors Accuracy: 1.0000\n","Classification Report for K-Nearest Neighbors:\n","               precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      1798\n","           1       1.00      1.00      1.00      1892\n","           2       1.00      1.00      1.00      1800\n","\n","    accuracy                           1.00      5490\n","   macro avg       1.00      1.00      1.00      5490\n","weighted avg       1.00      1.00      1.00      5490\n","\n","Training Support Vector Classifier...\n","Support Vector Classifier Accuracy: 1.0000\n","Classification Report for Support Vector Classifier:\n","               precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      1798\n","           1       1.00      1.00      1.00      1892\n","           2       1.00      1.00      1.00      1800\n","\n","    accuracy                           1.00      5490\n","   macro avg       1.00      1.00      1.00      5490\n","weighted avg       1.00      1.00      1.00      5490\n","\n","Training Random Forest...\n","Random Forest Accuracy: 1.0000\n","Classification Report for Random Forest:\n","               precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      1798\n","           1       1.00      1.00      1.00      1892\n","           2       1.00      1.00      1.00      1800\n","\n","    accuracy                           1.00      5490\n","   macro avg       1.00      1.00      1.00      5490\n","weighted avg       1.00      1.00      1.00      5490\n","\n","Training Decision Tree...\n","Decision Tree Accuracy: 1.0000\n","Classification Report for Decision Tree:\n","               precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      1798\n","           1       1.00      1.00      1.00      1892\n","           2       1.00      1.00      1.00      1800\n","\n","    accuracy                           1.00      5490\n","   macro avg       1.00      1.00      1.00      5490\n","weighted avg       1.00      1.00      1.00      5490\n","\n","Training Gradient Boosting...\n","Gradient Boosting Accuracy: 1.0000\n","Classification Report for Gradient Boosting:\n","               precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      1798\n","           1       1.00      1.00      1.00      1892\n","           2       1.00      1.00      1.00      1800\n","\n","    accuracy                           1.00      5490\n","   macro avg       1.00      1.00      1.00      5490\n","weighted avg       1.00      1.00      1.00      5490\n","\n","Training AdaBoost...\n","AdaBoost Accuracy: 0.9996\n","Classification Report for AdaBoost:\n","               precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      1798\n","           1       1.00      1.00      1.00      1892\n","           2       1.00      1.00      1.00      1800\n","\n","    accuracy                           1.00      5490\n","   macro avg       1.00      1.00      1.00      5490\n","weighted avg       1.00      1.00      1.00      5490\n","\n","Training MLP Classifier...\n","MLP Classifier Accuracy: 0.9998\n","Classification Report for MLP Classifier:\n","               precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      1798\n","           1       1.00      1.00      1.00      1892\n","           2       1.00      1.00      1.00      1800\n","\n","    accuracy                           1.00      5490\n","   macro avg       1.00      1.00      1.00      5490\n","weighted avg       1.00      1.00      1.00      5490\n","\n","\n","Best Classifier: Logistic Regression with accuracy: 1.0000\n"]}],"source":["from sklearn.metrics import classification_report, accuracy_score\n","\n","# List of classifiers to evaluate\n","classifiers = {\n","    'Logistic Regression': LogisticRegression(max_iter=1000),\n","    'K-Nearest Neighbors': KNeighborsClassifier(),\n","    'Support Vector Classifier': SVC(),\n","    'Random Forest': RandomForestClassifier(),\n","    'Decision Tree': DecisionTreeClassifier(),\n","    'Gradient Boosting': GradientBoostingClassifier(),\n","    'AdaBoost': AdaBoostClassifier(),\n","    'MLP Classifier': MLPClassifier(max_iter=1000)\n","}\n","\n","# Initialize variables to store results\n","best_classifier = None\n","best_accuracy = 0\n","\n","# Evaluate each classifier\n","for name, clf in classifiers.items():\n","    print(f\"Training {name}...\")\n","    \n","    # Train the classifier\n","    clf.fit(X_train_scaled, y_train)\n","    \n","    # Make predictions\n","    y_pred = clf.predict(X_test_scaled)\n","    \n","    # Evaluate the classifier\n","    accuracy = accuracy_score(y_test, y_pred)\n","    print(f\"{name} Accuracy: {accuracy:.4f}\")\n","    \n","    # Compare and store the best classifier\n","    if accuracy > best_accuracy:\n","        best_accuracy = accuracy\n","        best_classifier = name\n","\n","    # Print classification report\n","    print(f\"Classification Report for {name}:\\n\", classification_report(y_test, y_pred))\n","\n","# Print the best classifier\n","print(f\"\\nBest Classifier: {best_classifier} with accuracy: {best_accuracy:.4f}\")\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["K-Nearest Neighbors accuracy: 1.0000\n"]}],"source":["# Initialize and train the KNN classifier\n","knn = KNeighborsClassifier(n_neighbors=5)  # Adjust n_neighbors if needed\n","knn.fit(X_train_scaled, y_train)\n","\n","# Save the model\n","joblib.dump(knn, 'knn_classifier.pkl')\n","\n","# Save the scaler (optional, for consistent scaling during loading)\n","joblib.dump(scaler, 'scaler.pkl')\n","\n","# Evaluate the model\n","y_pred = knn.predict(X_test_scaled)\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f'K-Nearest Neighbors accuracy: {accuracy:.4f}')"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["def predict(input):\n","    # Load the model\n","    model = joblib.load('knn_classifier.pkl')\n","    \n","    # Load the scaler\n","    scaler = joblib.load('scaler.pkl')\n","    \n","    # Preprocess the input\n","    input_scaled = scaler.transform(input)\n","    \n","    # Make a prediction\n","    prediction = model.predict(input_scaled)\n","    \n","    return prediction"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Python310\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n","  warnings.warn(\n"]}],"source":["import numpy as np\n","\n","# Girdiyi string'ten listeye dönüştür ve her bir değeri float yap\n","random_example = \"173411.3,173556.5,48515.7,48483.5,48464.1,4186409.0,4315842.5,4455307.0,29183.5,29169.0,29157.4,70200.6,70168.7,70155.6,70193.5,70190.3,35211.3,35207.7,15525.0,15537.5,15546.4,4184.9,4179.6,4175.9,24318.7,24327.5,24347.4,20044.7,20027.5,20025.7,21372.0,21365.0,48472.9,48539.3,93449.1,93346.0,93102.7,13998.1,13993.3,13993.8,190217.3,190485.5,189828.4,42959.1,42972.5,43017.2,34900.1,34908.4,27585.3,27572.4,19001.7,19008.7,19013.3,25372.7,25374.9,25362.4,10963.3,10957.8,10956.8,22066.0,22073.6,22066.3,36451.5,36377.9,32.230000,39.090000\"\n","random_example_list = [float(x) for x in random_example.split(\",\")]\n","\n","# Veriyi numpy dizisine dönüştür ve 1 örnek, n özellik olacak şekilde yeniden şekillendir\n","random_example_array = np.array(random_example_list).reshape(1, -1)\n","\n","# Modelde tahmin yaparken bu veriyi kullan\n","prediction = predict(random_example_array)\n"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted class name: kolonya\n"]}],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"}},"nbformat":4,"nbformat_minor":2}
